{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":10262,"sourceType":"modelInstanceVersion","modelInstanceId":5172,"modelId":3533},{"sourceId":11371,"sourceType":"modelInstanceVersion","modelInstanceId":5171,"modelId":3533},{"sourceId":11375,"sourceType":"modelInstanceVersion","modelInstanceId":5172,"modelId":3533}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":672.253242,"end_time":"2024-02-21T10:06:37.294427","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-21T09:55:25.041185","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2024 Google LLC.","metadata":{"id":"60KmTK7o6ppd","papermill":{"duration":0.007422,"end_time":"2024-02-21T09:55:26.786189","exception":false,"start_time":"2024-02-21T09:55:26.778767","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"papermill":{"duration":0.012321,"end_time":"2024-02-21T09:55:26.80406","exception":false,"start_time":"2024-02-21T09:55:26.791739","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-25T06:18:28.741196Z","iopub.execute_input":"2024-02-25T06:18:28.741507Z","iopub.status.idle":"2024-02-25T06:18:28.745486Z","shell.execute_reply.started":"2024-02-25T06:18:28.74148Z","shell.execute_reply":"2024-02-25T06:18:28.744891Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<table class=\"tfo-notebook-buttons\" align=\"left\">\n  <td>\n    <a target=\"_blank\" href=\"https://www.kaggle.com/howecnchen/gemma-kaggle-tpu-only\"><img src=\"https://www.kaggle.com/static/images/logos/kaggle-logo-transparent-300.png\" height=\"32\" width=\"70\"/>Run in Kaggle</a>\n  </td>\n</table>","metadata":{"papermill":{"duration":0.005641,"end_time":"2024-02-21T09:55:26.815024","exception":false,"start_time":"2024-02-21T09:55:26.809383","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**原文在[此](https://www.kaggle.com/windmaple/gemma-kaggle-tpu-only).**","metadata":{}},{"cell_type":"markdown","source":"# Gemma insutruction tuning on Kaggle TPU using Chinese dataset\n\nThis notebook is an adapted from the official [Gemma distributed tuning tutorial](https://ai.google.dev/gemma/docs/distributed_tuning) and [Gemma Vertex AI tutorial](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_kerasnlp_to_vertexai.ipynb). It is meant to demonstrate how to instruction tune Gemma 2B (non-instruction tuned variant) on Kaggle TPU so that the finetuned model can better follow Chinese instructions.\n\nThis notebook is also available directly on [Kaggle](https://www.kaggle.com/windmaple/gemma-kaggle-tpu-only).","metadata":{"papermill":{"duration":0.005634,"end_time":"2024-02-21T09:55:26.825916","exception":false,"start_time":"2024-02-21T09:55:26.820282","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Overview\n\nGemma is a family of lightweight, state-of-the-art open models built from research and technology used to create Google Gemini models. Gemma can be further finetuned to suit specific needs. But Large Language Models, such as Gemma, can be very large in size and some of them may not fit on a sing accelerator for finetuning. In this case there are two general approaches for finetuning them:\n1. Parameter Efficient Fine-Tuning (PEFT), which seeks to shrink the effective model size by sacrificing some fidelity. LoRA falls in this category and the [Finetune Gemma models in Keras using LoRA](https://ai.google.dev/gemma/docs/lora_tuning) tutorial demonstrates how to finetune the Gemma 2B model `gemma_2b_en` with LoRA using KerasNLP on a single GPU.\n2. Full parameter finetuning with model parallelism. Model parallelism distributes a single model's weights across multiple devices and enables horizontal scaling. You can find out more about distributed training in this [Keras guide](https://keras.io/guides/distribution/).\n\nThis tutorial walks you through using Keras with a JAX backend to finetune the Gemma 7B model with LoRA and model-parallism distributed training on Google's Tensor Processing Unit (TPU). Note that LoRA can be turned off in this tutorial for a slower but more accurate full-parameter tuning.","metadata":{"id":"Tdlq6K0znh3O","papermill":{"duration":0.005633,"end_time":"2024-02-21T09:55:26.83679","exception":false,"start_time":"2024-02-21T09:55:26.831157","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Using accelerators\n\nTechnically you can use either TPU or GPU for this tutorial.\n\n### Notes on TPU environments\n\nGoogle has 3 products that provide TPUs:\n* [Colab](https://colab.sandbox.google.com/) provides TPU v2, which is not sufficient for this tutorial.\n* [Kaggle](https://www.kaggle.com/) offers TPU v3 for free and they work for this tutorial.\n* [Cloud TPU](https://cloud.google.com/tpu?hl=en) offers TPU v3 and newer generations. One way to set it up is:\n  1. Create a new [TPU VM](https://cloud.google.com/tpu/docs/managing-tpus-tpu-vm#tpu-vms)\n  2. Set up [SSH port forwarding](https://cloud.google.com/solutions/connecting-securely#port-forwarding-over-ssh) for your intended Jupyter server port\n  3. Install Jupyter and start it on the TPU VM, then connect to Colab through \"Connect to a local runtime\"\n\n### Notes on multi-GPU setup\n\nAlthough this tutorial focuses on the TPU use case, you can easily adapt it for your own needs if you have a multi-GPU machine.\n\nIf you prefer to work through Colab, it's also possible to provision a multi-GPU VM for Colab directly through \"Connect to a custom GCE VM\" in the Colab Connect menu.\n\n\nWe will focus on using the **free TPU from Kaggle** here.","metadata":{"id":"z-jBO5hmDwrc","papermill":{"duration":0.005425,"end_time":"2024-02-21T09:55:26.847611","exception":false,"start_time":"2024-02-21T09:55:26.842186","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Before you begin","metadata":{"papermill":{"duration":0.005257,"end_time":"2024-02-21T09:55:26.85841","exception":false,"start_time":"2024-02-21T09:55:26.853153","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Gemma setup\n\nTo complete this tutorial, you will first need to complete the setup instructions at [Gemma setup](https://ai.google.dev/gemma/docs/setup). The Gemma setup instructions show you how to do the following:\n\nGemma models are hosted by Kaggle. To use Gemma, request access on Kaggle:\n\n- Sign in or register at [kaggle.com](https://www.kaggle.com)\n- Open the [Gemma model card](https://www.kaggle.com/models/google/gemma) and select _\"Request Access\"_\n- Complete the consent form and accept the terms and conditions\n","metadata":{"id":"aKvTsIkL98BG","papermill":{"duration":0.005259,"end_time":"2024-02-21T09:55:26.869282","exception":false,"start_time":"2024-02-21T09:55:26.864023","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Installation\n\nInstall Keras and KerasNLP with the Gemma model.","metadata":{"id":"AO7a1Q4Yyc9Z","papermill":{"duration":0.005175,"end_time":"2024-02-21T09:55:26.880069","exception":false,"start_time":"2024-02-21T09:55:26.874894","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n!pip install -q tensorflow-cpu\n!pip install -q -U keras-nlp tensorflow-hub\n!pip install -q -U keras>=3\n!pip install -qU transformers\n!pip install -U sentencepiece","metadata":{"id":"WWEzVJR4Fx9g","papermill":{"duration":37.05282,"end_time":"2024-02-21T09:56:03.93859","exception":false,"start_time":"2024-02-21T09:55:26.88577","status":"completed"},"tags":[],"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-03-07T02:43:18.660565Z","iopub.execute_input":"2024-03-07T02:43:18.661295Z","iopub.status.idle":"2024-03-07T02:44:13.970301Z","shell.execute_reply.started":"2024-03-07T02:43:18.661247Z","shell.execute_reply":"2024-03-07T02:44:13.969199Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-nlp 0.8.1 requires keras-core, which is not installed.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\ntensorflow-cpu 2.15.0.post1 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nCollecting sentencepiece\n  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n\u001b[?25hInstalling collected packages: sentencepiece\nSuccessfully installed sentencepiece-0.2.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Set up Keras JAX backend","metadata":{"id":"fr9VnPm7FoMf","papermill":{"duration":0.006513,"end_time":"2024-02-21T09:56:03.951855","exception":false,"start_time":"2024-02-21T09:56:03.945342","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Import JAX and run a sanity check on TPU. Kaggle offers TPUv3-8 devices which have 8 TPU cores with 16GB of memory each.","metadata":{"id":"lbZsUvfhwL2D","papermill":{"duration":0.00599,"end_time":"2024-02-21T09:56:03.964473","exception":false,"start_time":"2024-02-21T09:56:03.958483","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import jax\n# 下一个格子里面会解释为什么我们需要 JAX\njax.devices()","metadata":{"id":"BK4MpHLKGujb","outputId":"a60376b8-0937-45fc-809b-33eaa92cbc6c","papermill":{"duration":8.126711,"end_time":"2024-02-21T09:56:12.097265","exception":false,"start_time":"2024-02-21T09:56:03.970554","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:44:13.972053Z","iopub.execute_input":"2024-03-07T02:44:13.972339Z","iopub.status.idle":"2024-03-07T02:44:22.395378Z","shell.execute_reply.started":"2024-03-07T02:44:13.972309Z","shell.execute_reply":"2024-03-07T02:44:22.394465Z"},"trusted":true},"outputs":[{"name":"stderr","text":"E0307 02:44:18.585609393     257 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2024-03-07T02:44:18.585591655+00:00\"}\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import os\n\n# The Keras 3 distribution API is only implemented for the JAX backend for now\n# Keras 3 分发 API 目前仅针对 JAX 后端实现\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\n# Pre-allocate 90% of TPU memory to minimize memory fragmentation and allocation\n# overhead\n# 预分配 90% 的 TPU 内存，以最大限度地减少内存碎片和分配开销\nos.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.9\"","metadata":{"id":"WEgg_OVIL2HY","papermill":{"duration":0.01342,"end_time":"2024-02-21T09:56:12.117529","exception":false,"start_time":"2024-02-21T09:56:12.104109","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:44:22.396486Z","iopub.execute_input":"2024-03-07T02:44:22.396843Z","iopub.status.idle":"2024-03-07T02:44:22.401146Z","shell.execute_reply.started":"2024-03-07T02:44:22.396813Z","shell.execute_reply":"2024-03-07T02:44:22.400290Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Load model","metadata":{"id":"wo1xkzr62hXN","papermill":{"duration":0.00603,"end_time":"2024-02-21T09:56:12.129531","exception":false,"start_time":"2024-02-21T09:56:12.123501","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import keras\nimport keras_nlp","metadata":{"id":"kFCmWEKdMA_Y","outputId":"57359fb1-ea3e-482a-aaf3-dcffc265a5ec","papermill":{"duration":8.153944,"end_time":"2024-02-21T09:56:20.315559","exception":false,"start_time":"2024-02-21T09:56:12.161615","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:44:22.402995Z","iopub.execute_input":"2024-03-07T02:44:22.403270Z","iopub.status.idle":"2024-03-07T02:44:29.852739Z","shell.execute_reply.started":"2024-03-07T02:44:22.403242Z","shell.execute_reply":"2024-03-07T02:44:29.851878Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### Notes on mixed precision training on NVIDIA GPUs\n\nWhen training on NVIDIA GPUs, mixed precision (`keras.mixed_precision.set_global_policy('mixed_bfloat16')`) can be used to speed up training with minimal effect on training quality. In most case, it is recommended to turn on mixed precision as it saves both memory and time. However, be aware that at small batch sizes, it can inflate memory usage by 1.5x (weights will be loaded twice, at half precision and full precision).\n\nFor inference, half-precision (`keras.config.set_floatx(\"bfloat16\")`) will work and save memory while mixed-precision is not applicable.","metadata":{"id":"bx3m8f1dB7nk","papermill":{"duration":0.005945,"end_time":"2024-02-21T09:56:20.327808","exception":false,"start_time":"2024-02-21T09:56:20.321863","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Uncomment the line below if you want to enable mixed precision training on GPUs\n# keras.mixed_precision.set_global_policy('mixed_bfloat16')","metadata":{"id":"T0lHxEDX03gp","papermill":{"duration":0.0122,"end_time":"2024-02-21T09:56:20.345701","exception":false,"start_time":"2024-02-21T09:56:20.333501","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-02-25T06:19:38.353483Z","iopub.execute_input":"2024-02-25T06:19:38.354011Z","iopub.status.idle":"2024-02-25T06:19:38.357466Z","shell.execute_reply.started":"2024-02-25T06:19:38.353977Z","shell.execute_reply":"2024-02-25T06:19:38.356742Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To load the model with the weights and tensors distributed across TPUs, first create a new `DeviceMesh`. `DeviceMesh` represents a collection of hardware devices configured for distributed computation and was introduced in Keras 3 as part of the unified distribution API.\n\nThe distribution API enables data and model parallelism, allowing for efficient scaling of deep learning models on multiple accelerators and hosts. It leverages the underlying framework (e.g. JAX) to distribute the program and tensors according to the sharding directives through a procedure called single program, multiple data (SPMD) expansion. Check out more details in the new [Keras 3 distribution API guide](https://keras.io/guides/distribution/).","metadata":{"id":"xrR8TpVS6uPs","papermill":{"duration":0.005852,"end_time":"2024-02-21T09:56:20.357594","exception":false,"start_time":"2024-02-21T09:56:20.351742","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Create a device mesh with (1, 8) shape so that the weights are sharded across\n# all 8 TPUs.\n# 创建形状为 (1, 8) 的设备网格，以便权重分布在所有 8 个 TPU 上。\ndevice_mesh = keras.distribution.DeviceMesh(\n    (1, 8),\n    [\"batch\", \"model\"],\n    devices=keras.distribution.list_devices())","metadata":{"id":"7gxEkpUiP1Qf","papermill":{"duration":0.012454,"end_time":"2024-02-21T09:56:20.375812","exception":false,"start_time":"2024-02-21T09:56:20.363358","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:44:29.853791Z","iopub.execute_input":"2024-03-07T02:44:29.854274Z","iopub.status.idle":"2024-03-07T02:44:29.858909Z","shell.execute_reply.started":"2024-03-07T02:44:29.854242Z","shell.execute_reply":"2024-03-07T02:44:29.858238Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"`LayoutMap` from the distribution API specifies how the weights and tensors should be sharded or replicated, using the string keys, for example, `token_embedding/embeddings` below, which are treated like regex to match tensor paths. Matched tensors are sharded with model dimensions (8 TPUs); others will be fully replicated.","metadata":{"id":"gTSJUwkC-7c6","papermill":{"duration":0.00582,"end_time":"2024-02-21T09:56:20.387661","exception":false,"start_time":"2024-02-21T09:56:20.381841","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_dim = \"model\"\n\nlayout_map = keras.distribution.LayoutMap(device_mesh)\n\n# Weights that match 'token_embedding/embeddings' will be sharded on 8 TPUs\nlayout_map[\"token_embedding/embeddings\"] = (None, model_dim)\n# Regex to match against the query, key and value matrices in the decoder\n# attention layers\nlayout_map[\"decoder_block.*attention.*(query|key|value).*kernel\"] = (\n    None, model_dim, None)\n\nlayout_map[\"decoder_block.*attention_output.*kernel\"] = (\n    None, None, model_dim)\nlayout_map[\"decoder_block.*ffw_gating.*kernel\"] = (model_dim, None)\nlayout_map[\"decoder_block.*ffw_linear.*kernel\"] = (None, model_dim)","metadata":{"id":"8Wgh8h0qQCcu","papermill":{"duration":0.013198,"end_time":"2024-02-21T09:56:20.406598","exception":false,"start_time":"2024-02-21T09:56:20.3934","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:44:29.859802Z","iopub.execute_input":"2024-03-07T02:44:29.860044Z","iopub.status.idle":"2024-03-07T02:44:29.874175Z","shell.execute_reply.started":"2024-03-07T02:44:29.860020Z","shell.execute_reply":"2024-03-07T02:44:29.873544Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"`ModelParallel` allows you to shard model weights or activation tensors across all devcies on the `DeviceMesh`. In this case, some of the Gemma 7B model weights are sharded across 8 TPU chips according the `layout_map` defined above. Now load the model in the distributed way.","metadata":{"id":"6n4Zlvk9ALhZ","papermill":{"duration":0.005938,"end_time":"2024-02-21T09:56:20.418485","exception":false,"start_time":"2024-02-21T09:56:20.412547","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model_parallel = keras.distribution.ModelParallel(\n    device_mesh, layout_map, batch_dim_name=\"batch\")\n\nkeras.distribution.set_distribution(model_parallel)\n\n# 从 `keras_nlp.models` 模块导入 `GemmaCausalLM` 类。\n# https://github.com/keras-team/keras-nlp/blob/v0.8.2/keras_nlp/models/gemma/gemma_causal_lm.py\n# 通过加载 \"gemma_2b_en\" 预设来创建一个 `gemma_lm` 对象。\ngemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")","metadata":{"id":"bu48vUnbQj0p","outputId":"fd216acb-852c-46f4-e8ac-2d8f91362d24","papermill":{"duration":145.668669,"end_time":"2024-02-21T09:58:46.092826","exception":false,"start_time":"2024-02-21T09:56:20.424157","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:44:29.875080Z","iopub.execute_input":"2024-03-07T02:44:29.875330Z","iopub.status.idle":"2024-03-07T02:45:21.459426Z","shell.execute_reply.started":"2024-03-07T02:44:29.875303Z","shell.execute_reply":"2024-03-07T02:45:21.458235Z"},"_kg_hide-output":true,"trusted":true},"outputs":[{"name":"stderr","text":"Attaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'config.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'model.weights.h5' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'tokenizer.json' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nAttaching 'assets/tokenizer/vocabulary.spm' from model 'keras/gemma/keras/gemma_2b_en/2' to your Kaggle notebook...\nnormalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Now verify that the model has been partitioned correctly. Let's take `decoder_block_1` as an example.","metadata":{"id":"ORCOIawAvpZ1","papermill":{"duration":0.006357,"end_time":"2024-02-21T09:58:46.105898","exception":false,"start_time":"2024-02-21T09:58:46.099541","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# 'decoder_block_1'代表解码器中的第一个解码器层。\n# 该层负责将编码器输出的中间表示转换为第一个输出token。\n# 为了区分不同的解码器层，通常会使用 'decoder_block_' 加上数字来命名每个解码器层。\n# 这种命名方式简洁明了，容易理解。具有通用性，可以应用于不同的 Transformer 模型。\ndecoder_block_1 = gemma_lm.backbone.get_layer('decoder_block_1')\nprint(type(decoder_block_1))\n# 遍历 decoder_block_1 中的每个权重变量\n# * 使用 variable.path 获取变量的路径，该路径指示变量在模型中的位置。\n# * 使用 str(variable.shape) 获取变量的形状，该形状指示变量包含多少个元素。\n# * 使用 str(variable.value.sharding.spec) 获取变量的分片规范，\n#   该规范指示变量的数据如何在训练期间分布在多个设备（例如 GPU）上。\n#\n# decoder_block_1.weights 输出包含模型中的所有权重变量，\n# 包括 layout_map 中包含的权重变量以及未包含的权重变量。\n# layout_map 可以用于将 decoder_block_1.weights 输出中的部分权重变量重新布局到不同的设备上。\nfor variable in decoder_block_1.weights:\n  print(f'{variable.path:<58}  {str(variable.shape):<16}  {str(variable.value.sharding.spec)}')","metadata":{"id":"DqT7TRHKvoMK","papermill":{"duration":0.014281,"end_time":"2024-02-21T09:58:46.126669","exception":false,"start_time":"2024-02-21T09:58:46.112388","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:45:21.460729Z","iopub.execute_input":"2024-03-07T02:45:21.461036Z","iopub.status.idle":"2024-03-07T02:45:21.468409Z","shell.execute_reply.started":"2024-03-07T02:45:21.461005Z","shell.execute_reply":"2024-03-07T02:45:21.467436Z"},"_kg_hide-input":true,"trusted":true},"outputs":[{"name":"stdout","text":"<class 'keras_nlp.src.models.gemma.gemma_decoder_block.GemmaDecoderBlock'>\ndecoder_block_1/pre_attention_norm/scale                    (2048,)           PartitionSpec(None,)\ndecoder_block_1/attention/query/kernel                      (8, 2048, 256)    PartitionSpec(None, 'model', None)\ndecoder_block_1/attention/key/kernel                        (1, 2048, 256)    PartitionSpec(None, 'model', None)\ndecoder_block_1/attention/value/kernel                      (1, 2048, 256)    PartitionSpec(None, 'model', None)\ndecoder_block_1/attention/attention_output/kernel           (8, 256, 2048)    PartitionSpec(None, None, 'model')\ndecoder_block_1/pre_ffw_norm/scale                          (2048,)           PartitionSpec(None,)\ndecoder_block_1/ffw_gating/kernel                           (2048, 16384)     PartitionSpec('model', None)\ndecoder_block_1/ffw_gating_2/kernel                         (2048, 16384)     PartitionSpec('model', None)\ndecoder_block_1/ffw_linear/kernel                           (16384, 2048)     PartitionSpec(None, 'model')\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Load instruction dataset","metadata":{}},{"cell_type":"code","source":"!wget -O baike.jsonl https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese/raw/main/baike.jsonl","metadata":{"execution":{"iopub.status.busy":"2024-03-07T02:45:21.469599Z","iopub.execute_input":"2024-03-07T02:45:21.469889Z","iopub.status.idle":"2024-03-07T02:45:24.264762Z","shell.execute_reply.started":"2024-03-07T02:45:21.469859Z","shell.execute_reply":"2024-03-07T02:45:24.263358Z"},"_kg_hide-input":true,"trusted":true},"outputs":[{"name":"stdout","text":"--2024-03-07 02:45:21--  https://huggingface.co/datasets/Hello-SimpleAI/HC3-Chinese/raw/main/baike.jsonl\nResolving huggingface.co (huggingface.co)... 65.8.243.90, 65.8.243.46, 65.8.243.92, ...\nConnecting to huggingface.co (huggingface.co)|65.8.243.90|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5005244 (4.8M) [text/plain]\nSaving to: ‘baike.jsonl’\n\nbaike.jsonl         100%[===================>]   4.77M  9.56MB/s    in 0.5s    \n\n2024-03-07 02:45:24 (9.56 MB/s) - ‘baike.jsonl’ saved [5005244/5005244]\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import re\nimport json\ndata = []\ncontext = \"你是一个知识丰富的人工智能助手，用户将用中文向你提问，你将根据你的知识用中文来如实回答问题。\\n\"\nwith open(\"baike.jsonl\") as file:\n    for line in file:\n        features = json.loads(line)        \n        template = context + \"问题：\\n{question}\\n答案：\\n{human_answers[0]}\"\n        data.append(template.format(**features))\n\n# Manually construct a test case; \n# Already made sure the finetuning dataset contains nothing about zsh\ntest_prompt = context + \"问题：\\n我有一个信息科学相关的问题，请用中文回答，什么是 zsh\\n答案：\\n\"\n# 4616 in total in baike split\ntrain_data = data[:4600]","metadata":{"_kg_hide-output":true,"id":"6MVJlsuSXCcf","outputId":"fcfda7bb-899e-4606-88e1-42eed9e70fc0","papermill":{"duration":43.816972,"end_time":"2024-02-21T09:59:56.217135","exception":false,"start_time":"2024-02-21T09:59:12.400163","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:46:12.921079Z","iopub.execute_input":"2024-03-07T02:46:12.921507Z","iopub.status.idle":"2024-03-07T02:46:12.981954Z","shell.execute_reply.started":"2024-03-07T02:46:12.921474Z","shell.execute_reply":"2024-03-07T02:46:12.980878Z"},"trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Inference before finetuning","metadata":{"id":"jc0ZzYIW0TSN","papermill":{"duration":0.005944,"end_time":"2024-02-21T09:58:46.139044","exception":false,"start_time":"2024-02-21T09:58:46.1331","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# 调用 `gemma_lm` 对象上的 `generate` 方法。\n# 它提供起始短语 \"test_prompt\" 并将 `max_length` 参数设置为 200。\n# 300 指示模型应该生成的最大单词数。\n# 模型将尝试造句，同时根据其训练数据保持事实一致性。\ngemma_lm.generate(test_prompt, max_length=200)","metadata":{"id":"ClaTyBp3Tgr4","outputId":"f2cf1ac7-469a-4c91-adff-74c2e3a1de89","papermill":{"duration":26.22201,"end_time":"2024-02-21T09:59:12.367352","exception":false,"start_time":"2024-02-21T09:58:46.145342","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:45:24.333665Z","iopub.execute_input":"2024-03-07T02:45:24.333917Z","iopub.status.idle":"2024-03-07T02:45:40.822321Z","shell.execute_reply.started":"2024-03-07T02:45:24.333893Z","shell.execute_reply":"2024-03-07T02:45:40.821186Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'你是一个知识丰富的人工智能助手，用户将用中文向你提问，你将根据你的知识用中文来如实回答问题。\\n问题：\\n我有一个信息科学相关的问题，请用中文回答，什么是 zsh\\n答案：\\nzsh 是一个命令行界面（CLI）的 shell，它支持许多命令行工具，包括 bash， fish， ksh， mksh， pdksh， tcsh， zsh， 和 yash。\\nzsh 是一个命令行界面（CLI）的 shell，它支持许多命令行工具，包括 bash， fish， ksh， mksh， pdksh， tcsh， zsh， 和 yash。\\nzsh 是一个命令行界面（CLI）的 shell，它支持许多命令行工具，包括 bash， fish， ksh， mksh， pdksh， tcsh， zsh， 和 yash。\\nzsh 是一个命令行界面（CLI）的 shell，它支持'"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"The model starts to repeat itself after a few sentences, which is not good.","metadata":{}},{"cell_type":"code","source":"#记录一下模型参数，以便微调之后进行比较\nmodel_json = gemma_lm.to_json()\nwith open(\"before-model.json\", \"w\") as f:\n    f.write(model_json)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T02:45:40.823551Z","iopub.execute_input":"2024-03-07T02:45:40.823838Z","iopub.status.idle":"2024-03-07T02:45:40.831593Z","shell.execute_reply.started":"2024-03-07T02:45:40.823809Z","shell.execute_reply":"2024-03-07T02:45:40.830597Z"},"trusted":true},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Finetune","metadata":{"id":"IcPCXCwvXC7t","papermill":{"duration":0.006625,"end_time":"2024-02-21T09:59:12.393943","exception":false,"start_time":"2024-02-21T09:59:12.387318","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Perform finetuning using [Low Rank Adaptation](https://arxiv.org/abs/2106.09685) (LoRA). LoRA is a fine-tuning technique which greatly reduces the number of trainable parameters for downstream tasks by freezing the full weights of the model and inserting a smaller number of new trainable weights into the model. Basically LoRA reparameterizes the larger full weight matrices by 2 smaller low-rank matrices AxB to train and this technique makes training much faster and more memory-efficient.","metadata":{"id":"xiLW0SpI1PfC","papermill":{"duration":0.032799,"end_time":"2024-02-21T09:59:56.345251","exception":false,"start_time":"2024-02-21T09:59:56.312452","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Enable LoRA for the model and set the LoRA rank to 4.\n# 该代码片段启用 Gemma 语言模型骨干网的低秩优化 (LORA)，秩为 4。\n# gemma_lm.backbone 指的是 Gemma 语言模型的骨干网，它是模型中负责处理和编码输入文本的主要部分。\n# enable_lora(rank=4) 是激活骨干网 LORA 的函数调用。\n#  * rank=4 参数指定用于 LORA 分解的秩。它定义了用于逼近原始权重矩阵的低秩因子的维数。\n#    通常，较低的秩值会导致更大的压缩，但也可能导致模型精度下降。\ngemma_lm.backbone.enable_lora(rank=4)","metadata":{"id":"3o_Gi3v_jp7s","papermill":{"duration":0.527031,"end_time":"2024-02-21T09:59:56.902475","exception":false,"start_time":"2024-02-21T09:59:56.375444","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:47:26.209909Z","iopub.execute_input":"2024-03-07T02:47:26.210526Z","iopub.status.idle":"2024-03-07T02:47:26.958200Z","shell.execute_reply.started":"2024-03-07T02:47:26.210475Z","shell.execute_reply":"2024-03-07T02:47:26.957126Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"**LORA 简介**：\n\nLORA 是一种用于压缩深度学习模型参数的技术，特别是权重矩阵。它通过将权重矩阵分解为两个低秩矩阵的乘积来实现，从而显着减少存储和训练模型所需的 parameters 数量。这对于以下方面是有益的：\n\n* 减少内存占用: LORA 可以显着减少存储模型所需的内存，使其更容易部署在内存资源有限的设备上。\n* 更快地训练: 通过减少参数数量，LORA 可能会导致更快的训练时间。\n\n**代码的影响**：\n\n通过启用秩为 4 的 LORA，该代码旨在压缩 Gemma 模型骨干网中的权重矩阵，这可能会导致：\n\n* 内存使用量减少。\n* 更快的训练时间（尽管这取决于各种因素）。\n\n**重要提示**：\n\n启用 LORA 也可能会引入权衡，可能会影响模型的准确性。因此，在应用 LORA 之后评估模型的性能至关重要，以确保其满足所需的准确性要求。\n\n**LORA秩的选取**：\n\n没有严格的规则，通常需要根据具体任务和模型进行调整。以下是一些影响秩选取的因素：\n\n**1. 任务复杂度**:\n\n* 对于简单任务，秩通常可以设置较低，例如 1 或 2。\n* 对于复杂任务，可能需要更高的秩来获得更好的精度，例如 4 或 8。\n\n**2. 模型大小**:\n\n* 对于较小的模型，秩通常可以设置较低。\n* 对于较大的模型，可能需要更高的秩来捕获更多信息。\n\n**3. 精度要求**:\n\n* 如果对精度要求不高，可以设置较低的秩。\n* 如果需要更高的精度，则需要设置更高的秩。\n\n**4. 计算资源**:\n\n* 较高的秩需要更多的计算资源进行训练和推理。\n* 需要根据实际情况权衡精度和计算资源之间的关系。\n\n**经验建议**:\n\n可以从较低的秩开始，然后根据需要逐渐增加。\n可以使用交叉验证来找到最佳的秩。\n可以参考其他类似任务的经验。\n\n**以下是一些具体的建议**：\n\n对于大多数自然语言处理任务，秩 4 或 8 是一个不错的起点。\n对于图像分类任务，秩 16 或 32 可能是必要的。\n对于语音识别任务，秩 64 或更高可能需要。\n需要注意的是，LORA 秩的选择是一个经验性过程，需要根据具体情况进行调整。\n\n**参考资料**：\n\nLORA: Low-Rank Optimization for Large Language Models: https://arxiv.org/abs/2104.08991\nLORA: A Low-Rank Adapter for Efficient and Accurate Large Language Model Training: https://arxiv.org/abs/2202.05954\n\n**总结**：\n\nLORA秩的选取没有固定的规则，需要根据任务复杂度、模型大小、精度要求和计算资源等因素进行调整。可以从较低的秩开始，然后根据需要逐渐增加，也可以参考其他类似任务的经验。","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"#接下来，使用通用的训练设置来调整 gemma_lm 模型以适应任务。\n#\n#AdamW 是基于 Transformer 的语言模型中常用的优化器。\n#为了考虑内存，调整了序列长度。\n#使用加权指标来处理潜在不平衡的训练数据集。\n\n# Fine-tune on the IMDb movie reviews dataset.\n\n# Limit the input sequence length to 128 to control memory usage.\n# 将模型可以处理的文本序列的最大长度限制为 128 个标记。 \n# 这通常是为了提高内存效率，特别是在使用像 Gemma 这样的大型语言模型时。\ngemma_lm.preprocessor.sequence_length = 128\n\n# Use AdamW (a common optimizer for transformer models).\n# keras.optimizers.AdamW设置了用于训练模型的优化器 AdamW。\n# * AdamW 是 Adam 优化器的变体，包括权重衰减。\n# * 权重衰减是一种正则化技术，有助于防止过拟合。\n# * 偏差和层归一化参数 (scale) 被排除在权重衰减之外，因为它们通常需要不同的学习率。\noptimizer = keras.optimizers.AdamW(\n    learning_rate=5e-5,\n    weight_decay=0.01,\n)\n# Exclude layernorm and bias terms from decay.\n# 告诉 AdamW 优化器将名为 “bias” 和 “scale” 的参数从权重衰减中排除。\n# 这些参数通常与 批量归一化层 相关联，而批量归一化层经常用于像 Gemma 这样的 Transformer 模型。将它们从权重衰减中排除有助于：\n# * 保持它们的原始学习率: 权重衰减会影响可训练参数的学习率。排除它们允许根据需要进行独立的学习率调整。\n# * 保持它们的有效性: 将权重衰减应用于 “bias” 和 “scale” 可能会对批量归一化层的性能产生负面影响。\noptimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n\n# 编译模型，并指定了：\n# * 要使用的损失函数：SparseCategoricalCrossentropy，适用于每个样本都属于一个类的多类分类任务。\n# * 优化器：配置的 AdamW 优化器。\n# * 训练过程中要跟踪的指标：SparseCategoricalAccuracy，根据多类预测来衡量准确性。\ngemma_lm.compile(\n    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    optimizer=optimizer,\n    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n)\ngemma_lm.summary()\n# 使用提供的 data 开始模型训练过程。\n# * epochs=5 该参数设置训练的 epoch 数。\n#   一个 epoch 是对整个训练数据集的完整遍历。在这里，模型将训练 5 个 epoch。\n# * batch_size=32 该参数定义训练期间使用的 batch 大小。一个 batch 是用于一次训练更新的训练数据子集。\n#   在这里，batch 大小为 32 表示模型将在每次处理 32 个训练示例后进行更新。\ngemma_lm.fit(train_data, epochs=5, batch_size=32)","metadata":{"_kg_hide-output":true,"id":"1-hQFy7hXWRl","outputId":"eb21b839-1e23-4be5-afcb-90a7bb0e4167","papermill":{"duration":362.718929,"end_time":"2024-02-21T10:05:59.651432","exception":false,"start_time":"2024-02-21T09:59:56.932503","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:47:30.736071Z","iopub.execute_input":"2024-03-07T02:47:30.736489Z","iopub.status.idle":"2024-03-07T02:55:50.950290Z","shell.execute_reply.started":"2024-03-07T02:47:30.736454Z","shell.execute_reply":"2024-03-07T02:55:50.949309Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        │   \u001b[38;5;34m2,507,536,384\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m524,288,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">524,288,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,507,536,384\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,507,536,384</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,363,968\u001b[0m (5.20 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,363,968</span> (5.20 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,506,172,416\u001b[0m (9.34 GB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,506,172,416</span> (9.34 GB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 834ms/step - loss: 2.9920 - sparse_categorical_accuracy: 0.4369\nEpoch 2/5\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 623ms/step - loss: 1.9053 - sparse_categorical_accuracy: 0.6308\nEpoch 3/5\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 620ms/step - loss: 1.8146 - sparse_categorical_accuracy: 0.6418\nEpoch 4/5\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 620ms/step - loss: 1.7925 - sparse_categorical_accuracy: 0.6428\nEpoch 5/5\n\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 620ms/step - loss: 1.7777 - sparse_categorical_accuracy: 0.6442\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7cf9b4667190>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"In total it took <10 mininutes.","metadata":{"id":"CnpeavB4fZ7Y","papermill":{"duration":0.137841,"end_time":"2024-02-21T10:05:59.925998","exception":false,"start_time":"2024-02-21T10:05:59.788157","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Inference after finetuning","metadata":{"id":"lBiOKlAy2MAe","papermill":{"duration":0.137064,"end_time":"2024-02-21T10:06:00.201917","exception":false,"start_time":"2024-02-21T10:06:00.064853","status":"completed"},"tags":[]}},{"cell_type":"code","source":"gemma_lm.generate(test_prompt, max_length=200)","metadata":{"id":"9yNyJ8CLXfw0","outputId":"f0a1c1e9-2221-4e3a-83df-829a47488b1c","papermill":{"duration":31.150786,"end_time":"2024-02-21T10:06:31.488004","exception":false,"start_time":"2024-02-21T10:06:00.337218","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-03-07T02:55:50.951870Z","iopub.execute_input":"2024-03-07T02:55:50.952135Z","iopub.status.idle":"2024-03-07T02:56:08.775628Z","shell.execute_reply.started":"2024-03-07T02:55:50.952110Z","shell.execute_reply":"2024-03-07T02:56:08.774450Z"},"trusted":true},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'你是一个知识丰富的人工智能助手，用户将用中文向你提问，你将根据你的知识用中文来如实回答问题。\\n问题：\\n我有一个信息科学相关的问题，请用中文回答，什么是 zsh\\n答案：\\nzsh（Zsh Shell）是一个命令行用户界面，在Linux和Unix操作系统上运行的shell程序，是Z shell（zsh）的缩写。 \\n它是一个基于POSIX规范的命令行用户界面，支持命令行参数和文件参数传递，支持标准命令的自动补齐。'"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"Now it gives much better answer in Chinese than the pretrained variant.","metadata":{"id":"inqB1e_v0xP5","papermill":{"duration":0.136614,"end_time":"2024-02-21T10:06:31.761087","exception":false,"start_time":"2024-02-21T10:06:31.624473","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#记录一下新的模型参数，以便进行比较\nmodel_json = gemma_lm.to_json()\nwith open(\"after-model.json\", \"w\") as f:\n    f.write(model_json)","metadata":{"execution":{"iopub.status.busy":"2024-03-07T03:01:30.445283Z","iopub.execute_input":"2024-03-07T03:01:30.445739Z","iopub.status.idle":"2024-03-07T03:01:30.451012Z","shell.execute_reply.started":"2024-03-07T03:01:30.445705Z","shell.execute_reply":"2024-03-07T03:01:30.450241Z"},"trusted":true},"outputs":[],"execution_count":26},{"cell_type":"code","source":"!pip install json_tools","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-03-07T03:21:32.350229Z","iopub.execute_input":"2024-03-07T03:21:32.351091Z","iopub.status.idle":"2024-03-07T03:21:37.389756Z","shell.execute_reply.started":"2024-03-07T03:21:32.351058Z","shell.execute_reply":"2024-03-07T03:21:37.388524Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Collecting json_tools\n  Downloading json_tools-0.4.1.tar.gz (7.2 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting colorama\n  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\nRequirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from json_tools) (1.16.0)\nBuilding wheels for collected packages: json_tools\n  Building wheel for json_tools (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for json_tools: filename=json_tools-0.4.1-py3-none-any.whl size=10287 sha256=1c4b0807f847b3988d9afd705e6b5b4178e394c550ca8fdf7ed93d708662e72e\n  Stored in directory: /root/.cache/pip/wheels/9a/38/dd/3e5cdf6112b06d0965456b456a2e8905e1076850910a39b987\nSuccessfully built json_tools\nInstalling collected packages: colorama, json_tools\nSuccessfully installed colorama-0.4.6 json_tools-0.4.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# 计算参数变化\nwith open(\"before-model.json\", \"r\") as f:\n    before_model_dict = json.load(f)\nwith open(\"after-model.json\", \"r\") as f:\n    after_model_dict = json.load(f)\n\nimport json\nimport json_tools\ndiff_value = json_tools.diff(before_model_dict, after_model_dict)\n# 输出微调前后的模型差异。\n# 目前看来，所有这些变化都是以牺牲准确度为前提提升训练速度。\n# 估计是为了演示而进行的调整。如果真的是为了生产环境的微调，这些参数大部分还是要改回去。\nprint(json.dumps(diff_value, indent=2))","metadata":{"execution":{"iopub.status.busy":"2024-03-07T03:23:40.260557Z","iopub.execute_input":"2024-03-07T03:23:40.260956Z","iopub.status.idle":"2024-03-07T03:23:40.268789Z","shell.execute_reply.started":"2024-03-07T03:23:40.260927Z","shell.execute_reply":"2024-03-07T03:23:40.267810Z"},"_kg_hide-input":true,"trusted":true},"outputs":[{"name":"stdout","text":"[\n    {\n        \"replace\": \"/config/preprocessor/config/sequence_length\",\n        \"value\": 128,\n        \"prev\": 8192\n    },\n    {\n        \"replace\": \"/compile_config/optimizer/class_name\",\n        \"value\": \"AdamW\",\n        \"prev\": \"Adam\"\n    },\n    {\n        \"replace\": \"/compile_config/optimizer/config/name\",\n        \"value\": \"adamw\",\n        \"prev\": \"adam\"\n    },\n    {\n        \"replace\": \"/compile_config/optimizer/config/learning_rate\",\n        \"value\": 4.999999873689376e-05,\n        \"prev\": 1.9999999494757503e-05\n    },\n    {\n        \"replace\": \"/compile_config/optimizer/config/weight_decay\",\n        \"value\": 0.01,\n        \"details\": \"type\",\n        \"prev\": null\n    },\n    {\n        \"replace\": \"/compile_config/metrics\",\n        \"value\": null,\n        \"details\": \"type\",\n        \"prev\": [\n            {\n                \"module\": \"keras.metrics\",\n                \"class_name\": \"SparseCategoricalAccuracy\",\n                \"config\": {\n                    \"name\": \"sparse_categorical_accuracy\",\n                    \"dtype\": null\n                },\n                \"registered_name\": null\n            }\n        ]\n    },\n    {\n        \"replace\": \"/compile_config/weighted_metrics\",\n        \"value\": [\n            {\n                \"module\": \"keras.metrics\",\n                \"class_name\": \"SparseCategoricalAccuracy\",\n                \"config\": {\n                    \"name\": \"sparse_categorical_accuracy\",\n                    \"dtype\": null\n                },\n                \"registered_name\": null\n            }\n        ],\n        \"details\": \"type\",\n        \"prev\": null\n    }\n]\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"## Convert to Hugging Face\n\nMany ppl prefer to use Hugging Face than Keras for whatever reason. It's easy to make the conversion.","metadata":{}},{"cell_type":"code","source":"# Finetuned model\nFINETUNED_MODEL_DIR = f\"./finetuned_gemma\"\nFINETUNED_WEIGHTS_PATH = f\"{FINETUNED_MODEL_DIR}/model.weights.h5\"\nFINETUNED_VOCAB_PATH = f\"{FINETUNED_MODEL_DIR}/vocabulary.spm\"\n\n# Converted model\nHUGGINGFACE_MODEL_DIR = f\"./gemma_huggingface\"\n\nMODEL_NAME = \"gemma_2b_en\"\n\n# Deduce model size from name format: \"gemma[_instruct]_{2b,7b}_en\"\nMODEL_SIZE = MODEL_NAME.split(\"_\")[-2]","metadata":{"execution":{"iopub.status.busy":"2024-02-25T06:29:23.402121Z","iopub.execute_input":"2024-02-25T06:29:23.402476Z","iopub.status.idle":"2024-02-25T06:29:23.407294Z","shell.execute_reply.started":"2024-02-25T06:29:23.402441Z","shell.execute_reply":"2024-02-25T06:29:23.40655Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Make sure the directory exists\n%mkdir -p $FINETUNED_MODEL_DIR\n\ngemma_lm.save_weights(FINETUNED_WEIGHTS_PATH)\n\ngemma_lm.preprocessor.tokenizer.save_assets(FINETUNED_MODEL_DIR)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T06:29:23.408213Z","iopub.execute_input":"2024-02-25T06:29:23.408476Z","iopub.status.idle":"2024-02-25T06:29:40.50459Z","shell.execute_reply.started":"2024-02-25T06:29:23.408449Z","shell.execute_reply":"2024-02-25T06:29:40.503242Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!du -shc $FINETUNED_MODEL_DIR/*","metadata":{"execution":{"iopub.status.busy":"2024-02-25T06:29:40.505917Z","iopub.execute_input":"2024-02-25T06:29:40.50619Z","iopub.status.idle":"2024-02-25T06:29:41.167062Z","shell.execute_reply.started":"2024-02-25T06:29:40.506162Z","shell.execute_reply":"2024-02-25T06:29:41.165605Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download the conversion script from KerasNLP tools\n!wget -nv -nc https://raw.githubusercontent.com/keras-team/keras-nlp/master/tools/gemma/export_gemma_to_hf.py\n\n# Run the conversion script\n# Note: it uses the PyTorch backend of Keras (hence the KERAS_BACKEND env variable)\n!KERAS_BACKEND=torch python export_gemma_to_hf.py \\\n    --weights_file $FINETUNED_WEIGHTS_PATH \\\n    --size $MODEL_SIZE \\\n    --vocab_path $FINETUNED_VOCAB_PATH \\\n    --output_dir $HUGGINGFACE_MODEL_DIR","metadata":{"execution":{"iopub.status.busy":"2024-02-25T06:29:41.168641Z","iopub.execute_input":"2024-02-25T06:29:41.16896Z","iopub.status.idle":"2024-02-25T06:34:15.362493Z","shell.execute_reply.started":"2024-02-25T06:29:41.16893Z","shell.execute_reply":"2024-02-25T06:34:15.361128Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import transformers\nmodel = transformers.GemmaForCausalLM.from_pretrained(\n    HUGGINGFACE_MODEL_DIR,\n    local_files_only=True,\n    device_map=\"auto\",  # Library \"accelerate\" to auto-select GPU\n)\ntokenizer = transformers.GemmaTokenizer.from_pretrained(\n    HUGGINGFACE_MODEL_DIR,\n    local_files_only=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T06:34:15.364068Z","iopub.execute_input":"2024-02-25T06:34:15.364391Z","iopub.status.idle":"2024-02-25T06:34:20.46251Z","shell.execute_reply.started":"2024-02-25T06:34:15.364361Z","shell.execute_reply":"2024-02-25T06:34:20.461326Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_transformers_model(\n    model: transformers.GemmaForCausalLM,\n    tokenizer: transformers.GemmaTokenizer,\n) -> None:   \n    inputs = tokenizer([test_prompt], return_tensors=\"pt\").to(model.device)\n    outputs = model.generate(**inputs, max_length=200)\n\n    output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    print(f\"{output}\\n{'- '*40}\")\n\n# This run on CPU so it is a bit slow\ntest_transformers_model(model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-25T06:34:20.463591Z","iopub.execute_input":"2024-02-25T06:34:20.464099Z","iopub.status.idle":"2024-02-25T06:34:59.576527Z","shell.execute_reply.started":"2024-02-25T06:34:20.464069Z","shell.execute_reply":"2024-02-25T06:34:59.575424Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Tis is very much similar to the KerasNLP output we had before, so I think our HF conversion worked.","metadata":{}},{"cell_type":"markdown","source":"# Final note\n\n* Here we used Gemma 2B. Technically you can use Gemma 7B, but sadly Kaggle only offers 20G of hard drive disk space, so you can't easily store the converted HF file.\n* The instruction-tuned variant of Gemma 2B that we didn't use does have some basic capability to follow Chinese instructions but the technique used here can be used to further enhance it.\n* TPU v3 is so much faster than the free T4 GPU on Google Colab. \n","metadata":{}}]}